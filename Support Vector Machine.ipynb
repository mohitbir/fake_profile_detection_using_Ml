{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect fake profiles in online social networks using Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import gender_guesser.detector as gender\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split,KFold,GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### function for reading dataset from csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_datasets():\n",
    "    \"\"\" Reads users profile from csv files \"\"\"\n",
    "    genuine_users = pd.read_csv(\"data/users.csv\")\n",
    "    fake_users = pd.read_csv(\"data/fusers.csv\")\n",
    "    # print genuine_users.columns\n",
    "    # print genuine_users.describe()\n",
    "    #print fake_users.describe()\n",
    "    x=pd.concat([genuine_users,fake_users])   \n",
    "    y=len(fake_users)*[0] + len(genuine_users)*[1]\n",
    "    return x,y\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### function for predicting sex using name of person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sex(name):\n",
    "    sex_predictor = gender.Detector(case_sensitive=False)\n",
    "    first_name= name.str.split(' ').str.get(0)\n",
    "    sex= first_name.apply(sex_predictor.get_gender)\n",
    "    sex_dict={'female':-2,'mostly_female':-1,'unknown':0,'mostly_male':1,'male':2,'andy':3}\n",
    "    sex_code = sex.map(sex_dict).astype(int)\n",
    "    return sex_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### function for feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(x):\n",
    "    lang_list = list(enumerate(np.unique(x['lang'])))   \n",
    "    lang_dict = { name : i for i, name in lang_list }             \n",
    "    x.loc[:,'lang_code'] = x['lang'].map( lambda x: lang_dict[x]).astype(int)    \n",
    "    x.loc[:,'sex_code']=predict_sex(x['name'])\n",
    "    feature_columns_to_use = ['statuses_count','followers_count','friends_count','favourites_count','listed_count','sex_code','lang_code']\n",
    "    x=x.loc[:,feature_columns_to_use]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### function for ploting learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\\n                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\\n    plt.figure()\\n    plt.title(title)\\n    if ylim is not None:\\n        plt.ylim(*ylim)\\n    plt.xlabel(\"Training examples\")\\n    plt.ylabel(\"Score\")\\n    train_sizes, train_scores, test_scores = learning_curve(\\n        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\\n    train_scores_mean = np.mean(train_scores, axis=1)\\n    train_scores_std = np.std(train_scores, axis=1)\\n    test_scores_mean = np.mean(test_scores, axis=1)\\n    test_scores_std = np.std(test_scores, axis=1)\\n    plt.grid()\\n\\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\\n                     train_scores_mean + train_scores_std, alpha=0.1,\\n                     color=\"r\")\\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\\n                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\\n    plt.plot(train_sizes, train_scores_mean, \\'o-\\', color=\"r\",\\n             label=\"Training score\")\\n    plt.plot(train_sizes, test_scores_mean, \\'o-\\', color=\"g\",\\n             label=\"Cross-validation score\")\\n\\n    plt.legend(loc=\"best\")\\n    return plt'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### function for plotting confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\\n    target_names=['Fake','Genuine']\\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\\n    plt.title(title)\\n    plt.colorbar()\\n    tick_marks = np.arange(len(target_names))\\n    plt.xticks(tick_marks, target_names, rotation=45)\\n    plt.yticks(tick_marks, target_names)\\n    plt.tight_layout()\\n    plt.ylabel('True label')\\n    plt.xlabel('Predicted label')\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    target_names=['Fake','Genuine']\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(target_names))\n",
    "    plt.xticks(tick_marks, target_names, rotation=45)\n",
    "    plt.yticks(tick_marks, target_names)\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### function for plotting ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def plot_roc_curve(y_test, y_pred):\\n    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\\n    print(\"False Positive rate: \",false_positive_rate)\\n    print(\"True Positive rate: \",true_positive_rate)\\n    \\n    roc_auc = auc(false_positive_rate, true_positive_rate)\\n\\n    plt.title(\\'Receiver Operating Characteristic\\')\\n    plt.plot(false_positive_rate, true_positive_rate, \\'b\\',\\n    label=\\'AUC = %0.2f\\'% roc_auc)\\n    plt.legend(loc=\\'lower right\\')\\n    plt.plot([0,1],[0,1],\\'r--\\')\\n    plt.xlim([-0.1,1.2])\\n    plt.ylim([-0.1,1.2])\\n    plt.ylabel(\\'True Positive Rate\\')\\n    plt.xlabel(\\'False Positive Rate\\')\\n    plt.show()'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def plot_roc_curve(y_test, y_pred):\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    print(\"False Positive rate: \",false_positive_rate)\n",
    "    print(\"True Positive rate: \",true_positive_rate)\n",
    "    \n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(false_positive_rate, true_positive_rate, 'b',\n",
    "    label='AUC = %0.2f'% roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.xlim([-0.1,1.2])\n",
    "    plt.ylim([-0.1,1.2])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Function for training data using Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def train(X_train,y_train,X_test):\\n    \"\"\" Trains and predicts dataset with a SVM classifier \"\"\"\\n    # Scaling features\\n    X_train=preprocessing.scale(X_train)\\n    X_test=preprocessing.scale(X_test)\\n\\n    Cs = 10.0 ** np.arange(-2,3,.5)\\n    gammas = 10.0 ** np.arange(-2,3,.5)\\n    param = [{\\'gamma\\': gammas, \\'C\\': Cs}]\\n    cvk = KFold(n_splits=5,shuffle=True)\\n    classifier = SVC()\\n    clf = GridSearchCV(classifier,param_grid=param,cv=cvk)\\n    clf.fit(X_train,y_train)\\n    print(\"The best classifier is: \",clf.best_estimator_)\\n    clf.best_estimator_.fit(X_train,y_train)\\n    # Estimate score\\n    scores = cross_validation.cross_val_score(clf.best_estimator_, X_train,y_train, cv=5)\\n    print(scores)\\n    print(\\'Estimated score: %0.5f (+/- %0.5f)\\' % (scores.mean(), scores.std() / 2))\\n    title = \\'Learning Curves (SVM, rbf kernel, $\\\\gamma=%.6f$)\\' %clf.best_estimator_.gamma\\n    plot_learning_curve(clf.best_estimator_, title, X_train, y_train, cv=5)\\n    plt.show()\\n    # Predict class\\n    y_pred = clf.best_estimator_.predict(X_test)\\n    return y_test,y_pred'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''def train(X_train,y_train,X_test):\n",
    "    \"\"\" Trains and predicts dataset with a SVM classifier \"\"\"\n",
    "    # Scaling features\n",
    "    X_train=preprocessing.scale(X_train)\n",
    "    X_test=preprocessing.scale(X_test)\n",
    "\n",
    "    Cs = 10.0 ** np.arange(-2,3,.5)\n",
    "    gammas = 10.0 ** np.arange(-2,3,.5)\n",
    "    param = [{'gamma': gammas, 'C': Cs}]\n",
    "    cvk = KFold(n_splits=5,shuffle=True)\n",
    "    classifier = SVC()\n",
    "    clf = GridSearchCV(classifier,param_grid=param,cv=cvk)\n",
    "    clf.fit(X_train,y_train)\n",
    "    print(\"The best classifier is: \",clf.best_estimator_)\n",
    "    clf.best_estimator_.fit(X_train,y_train)\n",
    "    # Estimate score\n",
    "    scores = cross_validation.cross_val_score(clf.best_estimator_, X_train,y_train, cv=5)\n",
    "    print(scores)\n",
    "    print('Estimated score: %0.5f (+/- %0.5f)' % (scores.mean(), scores.std() / 2))\n",
    "    title = 'Learning Curves (SVM, rbf kernel, $\\gamma=%.6f$)' %clf.best_estimator_.gamma\n",
    "    plot_learning_curve(clf.best_estimator_, title, X_train, y_train, cv=5)\n",
    "    plt.show()\n",
    "    # Predict class\n",
    "    y_pred = clf.best_estimator_.predict(X_test)\n",
    "    return y_test,y_pred'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading datasets.....\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"reading datasets.....\\n\")\n",
    "x,y=read_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting featues.....\n",
      "\n",
      "Index(['statuses_count', 'followers_count', 'friends_count',\n",
      "       'favourites_count', 'listed_count', 'sex_code', 'lang_code'],\n",
      "      dtype='object')\n",
      "       statuses_count  followers_count  friends_count  favourites_count  \\\n",
      "count     2818.000000      2818.000000    2818.000000       2818.000000   \n",
      "mean      1672.198368       371.105039     395.363023        234.541164   \n",
      "std       4884.669157      8022.631339     465.694322       1445.847248   \n",
      "min          0.000000         0.000000       0.000000          0.000000   \n",
      "25%         35.000000        17.000000     168.000000          0.000000   \n",
      "50%         77.000000        26.000000     306.000000          0.000000   \n",
      "75%       1087.750000       111.000000     519.000000         37.000000   \n",
      "max      79876.000000    408372.000000   12773.000000      44349.000000   \n",
      "\n",
      "       listed_count     sex_code    lang_code  \n",
      "count   2818.000000  2818.000000  2818.000000  \n",
      "mean       2.818666    -0.136977     2.851313  \n",
      "std       23.480430     1.738406     1.992950  \n",
      "min        0.000000    -2.000000     0.000000  \n",
      "25%        0.000000    -2.000000     1.000000  \n",
      "50%        0.000000     0.000000     1.000000  \n",
      "75%        1.000000     2.000000     5.000000  \n",
      "max      744.000000     3.000000     7.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"extracting featues.....\\n\")\n",
    "x=extract_features(x)\n",
    "print(x.columns)\n",
    "print(x.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(x, y, test_size=0.20, random_state=44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HimanshuKumar\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7801418439716312"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc=SVC()\n",
    "svc.fit(X_train,y_train)\n",
    "pred=svc.predict(X_test)\n",
    "accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test,y_pred = train(X_train,y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy score',accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test, y_pred)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "plot_confusion_matrix(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)\n",
    "plot_confusion_matrix(cm_normalized, title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred, target_names=['Fake','Genuine']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_roc_curve(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
